{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09612987 -0.34432    -0.41709552 -0.71584526  1.95241853]\n",
      "1.047868117214116\n",
      "(1000, 5) (1000,)\n"
     ]
    }
   ],
   "source": [
    "num_features = 5\n",
    "num_samples = 1000\n",
    "\n",
    "model_a = np.random.normal(size=(num_features))\n",
    "model_c =np.random.normal()\n",
    "\n",
    "print(model_a)\n",
    "print(model_c)\n",
    "\n",
    "x_train = np.random.normal(size=(num_samples,num_features))*100\n",
    "y_train = x_train @ model_a + model_c + np.random.normal(size= num_samples)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "    with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.converted_call(ag__.ld(tf).tensordot, (ag__.ld(x), ag__.ld(a)), dict(axes=1), fscope) + ag__.ld(c))\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n",
      "Epoch: 0 Loss: 48559.37890625\n",
      "Epoch: 1000 Loss: 23864.33203125\n",
      "Epoch: 2000 Loss: 11665.0830078125\n",
      "Epoch: 3000 Loss: 5067.525390625\n",
      "Epoch: 4000 Loss: 1681.0235595703125\n",
      "Epoch: 5000 Loss: 340.1350402832031\n",
      "Epoch: 6000 Loss: 28.919628143310547\n",
      "Epoch: 7000 Loss: 1.4172924757003784\n",
      "Epoch: 8000 Loss: 0.9491111636161804\n",
      "Epoch: 9000 Loss: 0.9486059546470642\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.zeros(shape=(num_features,)),name=\"a\", trainable=True, dtype=tf.float32)\n",
    "c = tf.Variable(tf.zeros(shape=(1,)),name =\"c\", trainable=True, dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    return tf.tensordot(x,a,axes=1)+c\n",
    "\n",
    "print(tf.autograph.to_code(f.python_function))\n",
    "\n",
    "variables = [a,c]\n",
    "\n",
    "optimizer = tf.optimizers.Adam(0.0005)\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "for i in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = f(tf.cast(x_train,tf.float32))\n",
    "        loss = loss_object(tf.cast(y_train,tf.float32),y_pred)\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(grads, variables))\n",
    "        if i %1000 ==0: \n",
    "            print('Epoch: {} Loss: {}'.format(i,loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09616287 -0.34370005 -0.41769886 -0.71545637  1.952631  ] [1.0293131]\n",
      "[-0.09612987 -0.34432    -0.41709552 -0.71584526  1.95241853] [1.047868117214116]\n"
     ]
    }
   ],
   "source": [
    "print(a.numpy(),c.numpy())\n",
    "print(model_a,[model_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 1.018e+07\n",
      "Date:                Thu, 08 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        10:12:43   Log-Likelihood:                -1392.6\n",
      "No. Observations:                1000   AIC:                             2797.\n",
      "Df Residuals:                     994   BIC:                             2827.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0293      0.031     33.269      0.000       0.969       1.090\n",
      "x1            -0.0962      0.000   -300.899      0.000      -0.097      -0.096\n",
      "x2            -0.3437      0.000  -1131.269      0.000      -0.344      -0.343\n",
      "x3            -0.4177      0.000  -1277.357      0.000      -0.418      -0.417\n",
      "x4            -0.7155      0.000  -2355.782      0.000      -0.716      -0.715\n",
      "x5             1.9526      0.000   6347.287      0.000       1.952       1.953\n",
      "==============================================================================\n",
      "Omnibus:                        0.099   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.952   Jarque-Bera (JB):                0.067\n",
      "Skew:                          -0.019   Prob(JB):                        0.967\n",
      "Kurtosis:                       3.012   Cond. No.                         105.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [ 1.02930796 -0.09616272 -0.34370015 -0.41769911 -0.71545564  1.95263618]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(x_train)).fit()\n",
    "print(model.summary(),model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': False,\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'coef_': array([-0.09616272, -0.34370015, -0.41769911, -0.71545564,  1.95263618]),\n",
       " '_residues': 948.6051770079714,\n",
       " 'rank_': 5,\n",
       " 'singular_': array([3328.70197132, 3219.05337649, 3123.49282785, 3036.92817258,\n",
       "        2962.65870789]),\n",
       " 'intercept_': 1.0293079584369336}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train,y_train)\n",
    "vars(regr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 948.6051770107861\n",
       " hess_inv: array([[ 5.32701776e-08, -1.95384782e-10,  5.38472996e-10,\n",
       "        -1.67637280e-10,  1.35901083e-09,  1.64538529e-08],\n",
       "       [-1.95384803e-10,  4.85411501e-08,  3.53363462e-10,\n",
       "        -3.15147328e-10, -5.54151408e-10,  2.43846328e-07],\n",
       "       [ 5.38472991e-10,  3.53363442e-10,  5.60314961e-08,\n",
       "        -7.26935641e-10, -1.82895062e-09,  3.96478126e-08],\n",
       "       [-1.67637287e-10, -3.15147322e-10, -7.26935653e-10,\n",
       "         4.83066576e-08,  3.60592150e-09,  1.41665175e-08],\n",
       "       [ 1.35901082e-09, -5.54151404e-10, -1.82895063e-09,\n",
       "         3.60592151e-09,  4.95722371e-08,  1.89708363e-08],\n",
       "       [ 1.64538530e-08,  2.43846329e-07,  3.96478126e-08,\n",
       "         1.41665176e-08,  1.89708364e-08,  3.96816931e-04]])\n",
       "      jac: array([ 2.74658203e-04,  1.90734863e-04, -4.57763672e-05,  1.60217285e-04,\n",
       "        7.62939453e-05, -2.28881836e-05])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 612\n",
       "      nit: 11\n",
       "     njev: 75\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([-0.09616272, -0.34370015, -0.41769911, -0.71545565,  1.95263617,\n",
       "        1.02930797])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def cost(a,x,y):\n",
    "    predict = a[-1] + x@a[:-1]\n",
    "    return sum((predict-y)**2)\n",
    "\n",
    "minimize(cost, [0,0,0,0,0,0], args=(x_train,y_train),method='BFGS', options={'maxiter': 500})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
