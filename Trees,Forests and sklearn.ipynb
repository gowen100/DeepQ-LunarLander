{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "Data Shapes - Features (150, 4) Target: (150,) \n",
      "Iris labels are : [0 1 2]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "\n",
    "print(iris.keys())\n",
    "print(\"Data Shapes - Features {} Target: {} \".format(iris.data.shape,iris.target.shape))\n",
    "print(\"Iris labels are :\",pd.unique(iris.target))\n",
    "print(iris.feature_names)\n",
    "\n",
    "x_train, x_test ,y_train, y_test  =train_test_split(iris.data,iris.target,test_size = .33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is: \n",
      "[[ 0.67809169  1.5222555  -2.06468758 -0.94059062]\n",
      " [ 0.42129027 -0.02073601  0.06986399 -0.88364382]\n",
      " [-1.09938196 -1.50151949  1.99482359  1.82423444]]\n",
      "\n",
      "Accuracy is : 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(fit_intercept = False)\n",
    "lr_model.fit(x_train, y_train)\n",
    "print(\"Matrix is: \\n{}\\n\".format(lr_model.coef_))\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, lr_model.predict(x_test)))\n",
    "\n",
    "#print(vars(lr_model).keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] (150,)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239455\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  150\n",
      "Model:                          Logit   Df Residuals:                      148\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 27 May 2021   Pseudo R-squ.:                  0.6238\n",
      "Time:                        21:00:40   Log-Likelihood:                -35.918\n",
      "converged:                       True   LL-Null:                       -95.477\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.869e-28\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -27.8285      4.828     -5.765      0.000     -37.290     -18.367\n",
      "x1             5.1757      0.893      5.793      0.000       3.425       6.927\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "binary_y = iris.target\n",
    "binary_y[binary_y==2] = 1\n",
    "print(pd.unique(binary_y),binary_y.shape)\n",
    "\n",
    "logit = sm.Logit(binary_y,sm.add_constant(iris.data[:,:1], prepend = True))\n",
    "sm_coefs = logit.fit()\n",
    "print(sm_coefs.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- petal width (cm) <= 0.75\n",
      "|   |--- class: 0\n",
      "|--- petal width (cm) >  0.75\n",
      "|   |--- petal width (cm) <= 1.65\n",
      "|   |   |--- class: 1\n",
      "|   |--- petal width (cm) >  1.65\n",
      "|   |   |--- class: 2\n",
      "\n",
      "Accuracy is : 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "decision_tree = decision_tree.fit(x_train, y_train)\n",
    "r = export_text(decision_tree, feature_names=iris['feature_names'])\n",
    "print(r)\n",
    "\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, decision_tree.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf= RandomForestClassifier(n_estimators=50,max_depth=2,max_features=.5)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "#print(vars(clf).keys())\n",
    "\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbt = GradientBoostingClassifier(learning_rate =0.05,n_estimators=50,max_depth=2,min_samples_split=5,max_features=0.5)\n",
    "gbt = gbt.fit(x_train, y_train)\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, gbt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from IPython.display import clear_output\n",
    "\n",
    "            \n",
    "def update_progress(progress):\n",
    "    bar_length = 30\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "    \n",
    "class progress_bar(Callback):\n",
    "        \n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            update_progress((epoch+1)/500)\n",
    "\n",
    "progress = progress_bar()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##############################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "nn_model = Sequential([\n",
    "        Input(shape =(4,)),\n",
    "        Dense(128,activation='relu'),\n",
    "        Dense(128,activation='relu'),\n",
    "        Dense(3,activation='softmax')\n",
    "    ])\n",
    "\n",
    "nn_model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=[\"sparse_categorical_accuracy\"])\n",
    "history= nn_model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=500,callbacks=[progress], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "fig.suptitle('Neural Net Performace',fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "ax[0].plot(history.history['sparse_categorical_accuracy'])\n",
    "ax[0].plot(history.history['val_sparse_categorical_accuracy'])\n",
    "ax[0].set_title('accuracy vs. epochs',fontsize=18)\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Training', 'Validation'], loc='upper right')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Loss vs. epochs',fontsize=18)\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Training', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is :\", nn_model.evaluate(x_test,y_test,verbose= False)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train)\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, gnb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', activation = 'relu',hidden_layer_sizes=(128,128),max_iter=500)\n",
    "\n",
    "mlp = mlp.fit(x_train, y_train)\n",
    "print(\"Accuracy is :\",sk.metrics.accuracy_score(y_test, mlp.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 100   0\n",
      "100   0   0\n",
      "  0 100   0\n",
      "  0  54  46\n",
      "  0   6  94\n",
      "100   0   0\n",
      "  0   0 100\n",
      "100   0   0\n",
      "  0 100   0\n",
      "  0  67  33\n",
      "  0 100   0\n",
      "  0 100   0\n",
      "  0   0 100\n",
      "  0   0 100\n",
      "  0 100   0\n",
      "  0 100   0\n",
      "100   0   0\n",
      "  0 100   0\n",
      "100   0   0\n",
      "  0   0 100\n",
      "100   0   0\n",
      "100   0   0\n",
      "  0  25  75\n",
      "100   0   0\n",
      "  0 100   0\n",
      "  0 100   0\n",
      "  0 100   0\n",
      "  0   0 100\n",
      "  0   0 100\n",
      "  0 100   0\n",
      "  0 100   0\n",
      "  0  15  85\n",
      "  0  99   1\n",
      "100   0   0\n",
      "  0   1  99\n",
      "  0   0 100\n",
      "100   0   0\n",
      "100   0   0\n",
      "100   0   0\n",
      "  1  99   0\n",
      "  0   0 100\n",
      "  0 100   0\n",
      "100   0   0\n",
      "100   0   0\n",
      "100   0   0\n",
      "100   0   0\n",
      "  0   0 100\n",
      "  0   0 100\n",
      "100   0   0\n",
      "  0 100   0\n"
     ]
    }
   ],
   "source": [
    "for x in [\"{:3.0f} {:3.0f} {:3.0f}\".format(*i*100) for i in mlp.predict_proba(x_test)]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03716794401407242, 1.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.evaluate(x_test,y_test,verbose= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.functional.Functional)\n",
      " |  Sequential(*args, **kwargs)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
      " |  \n",
      " |  `Sequential` provides training and inference features on this model.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> # Afterwards, we do automatic shape inference:\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  \n",
      " |  >>> # This is identical to the following:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  \n",
      " |  >>> # Note that you can also omit the `input_shape` argument.\n",
      " |  >>> # In that case the model doesn't have any weights until the first call\n",
      " |  >>> # to a training/evaluation method (since it isn't yet built):\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> # model.weights not created yet\n",
      " |  \n",
      " |  >>> # Whereas if you specify the input shape, the model gets built\n",
      " |  >>> # continuously as you are adding layers:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  >>> # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  >>> # choose to manually build your model by calling\n",
      " |  >>> # `build(batch_input_shape)`:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> model.build((None, 16))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  ```python\n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
      " |  # or the first time you call the model on some input data.\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.functional.Functional\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Creates a `Sequential` model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        layers: Optional list of layers to add to the model.\n",
      " |        name: Optional name for the model.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Args:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
      " |           shapes are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, TensorShape, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.functional.Functional:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Args:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead.\n",
      " |            At most, one full epoch will be run each\n",
      " |            execution. If a number larger than the size of the epoch is passed,\n",
      " |            the execution will be truncated to the size of the epoch.\n",
      " |            Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |            will only be called every `N` batches\n",
      " |            (i.e. before/after each `tf.function` execution).\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |          **kwargs: Unused at this time.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      `Model.evaluate` is not yet supported with\n",
      " |      `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
      " |              callable that takes a single argument of type\n",
      " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
      " |              `DatasetCreator` should be used when users prefer to specify the\n",
      " |              per-replica batching and sharding logic for the `Dataset`.\n",
      " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
      " |              information.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below. If using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
      " |            `DatasetCreator` type is supported for `x`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so verbose=2 is\n",
      " |              recommended when not running interactively (eg, in a production\n",
      " |              environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |              Callbacks with batch-level calls are currently unsupported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`, and users are\n",
      " |              advised to implement epoch-level calls instead with an appropriate\n",
      " |              `steps_per_epoch` value.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |              `validation_split` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
      " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.\n",
      " |                - A `tf.data.Dataset`.\n",
      " |                - A Python generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      " |              `validation_data` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator or an object of tf.data.Dataset.\n",
      " |              'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs. `steps_per_epoch=None` is not supported when using\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections.abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`). This can also be a path to a SavedModel\n",
      " |              saved from `model.save`.\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      `Model.predict` is not yet supported with\n",
      " |      `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |                the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
