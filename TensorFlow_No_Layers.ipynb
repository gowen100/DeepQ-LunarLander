{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TensorFlow_No_Layers.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowen100/Machine-Learning/blob/master/TensorFlow_No_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bIlMFGqHoMU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwp5wbEiHoMX",
        "outputId": "f0c615f4-42be-4ac8-b341-5b4058a98201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#set up multivariate linear regression example data \n",
        "\n",
        "#define the dataset size\n",
        "num_features = 6\n",
        "num_samples = 10000\n",
        "\n",
        "#define dataset parameters \n",
        "model_a = np.random.normal(size=(num_features))\n",
        "model_c =np.random.normal()\n",
        "\n",
        "print(\"model a is {}\".format(model_a))\n",
        "print(\"model c is {}\".format(model_c))\n",
        "\n",
        "# create some random initial values and then work out the result adding in some random noise\n",
        "x_train = np.random.normal(size=(num_samples,num_features))*100\n",
        "y_train = x_train @ model_a + model_c + np.random.normal(size= num_samples)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model a is [ 0.76768127 -0.50678936  0.47532782  0.43127988  0.12477923 -0.1184996 ]\n",
            "model c is 0.2644701633703223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5g8mx1UHoMY",
        "outputId": "5c3cc021-9167-4a53-9eeb-59d6db36fd8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#use tensorflow to compute gradients and optimise the fit\n",
        "\n",
        "a = tf.Variable(tf.zeros(shape=(num_features,)),name=\"a\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(tf.zeros(shape=(1,)),name =\"c\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def f(x):\n",
        "    return tf.tensordot(x,a,axes=1)+c\n",
        "\n",
        "#print(tf.autograph.to_code(f.python_function))\n",
        "\n",
        "variables = [a,c]\n",
        "\n",
        "optimizer = tf.optimizers.Adam(0.005)\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "for i in range(1000):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = f(tf.cast(x_train,tf.float32))\n",
        "        loss = loss_object(tf.cast(y_train,tf.float32),y_pred)\n",
        "        grads = tape.gradient(loss, variables)\n",
        "        optimizer.apply_gradients(zip(grads, variables))\n",
        "        if i %100 ==0: \n",
        "            print('Epoch: {} Loss: {}'.format(i,loss.numpy()))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 13011.8203125\n",
            "Epoch: 100 Loss: 1409.5523681640625\n",
            "Epoch: 200 Loss: 106.43506622314453\n",
            "Epoch: 300 Loss: 5.155116558074951\n",
            "Epoch: 400 Loss: 1.0517330169677734\n",
            "Epoch: 500 Loss: 0.982807993888855\n",
            "Epoch: 600 Loss: 0.9822824001312256\n",
            "Epoch: 700 Loss: 0.9822757840156555\n",
            "Epoch: 800 Loss: 0.982275664806366\n",
            "Epoch: 900 Loss: 0.9822757840156555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajCFRt0yHoMZ",
        "outputId": "ea3cbfae-e6e0-481a-8b30-18d3e20bfc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Model fit:',a.numpy(),c.numpy())\n",
        "print('True :    ',model_a,[model_c])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model fit: [ 0.76783264 -0.506731    0.47550273  0.43135658  0.12464958 -0.11853882] [0.26828253]\n",
            "True :     [ 0.76768127 -0.50678936  0.47532782  0.43127988  0.12477923 -0.1184996 ] [0.2644701633703223]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSkjnuMwHoMZ",
        "outputId": "daa1bc0a-cd74-42d5-ce03-1aa26ee75008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# statsmodels OLS .. remember to add in the constant\n",
        "import statsmodels.api as sm\n",
        "\n",
        "model = sm.OLS(y_train, sm.add_constant(x_train)).fit()\n",
        "print(model.summary(),model.params)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       1.000\n",
            "Model:                            OLS   Adj. R-squared:                  1.000\n",
            "Method:                 Least Squares   F-statistic:                 2.205e+07\n",
            "Date:                Fri, 29 Jan 2021   Prob (F-statistic):               0.00\n",
            "Time:                        17:11:56   Log-Likelihood:                -14100.\n",
            "No. Observations:               10000   AIC:                         2.821e+04\n",
            "Df Residuals:                    9993   BIC:                         2.826e+04\n",
            "Df Model:                           6                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2683      0.010     27.053      0.000       0.249       0.288\n",
            "x1             0.7678   9.86e-05   7788.196      0.000       0.768       0.768\n",
            "x2            -0.5067   9.95e-05  -5090.905      0.000      -0.507      -0.507\n",
            "x3             0.4755   9.89e-05   4805.567      0.000       0.475       0.476\n",
            "x4             0.4314   9.85e-05   4380.507      0.000       0.431       0.432\n",
            "x5             0.1246   9.94e-05   1254.243      0.000       0.124       0.125\n",
            "x6            -0.1185   9.74e-05  -1216.729      0.000      -0.119      -0.118\n",
            "==============================================================================\n",
            "Omnibus:                        1.358   Durbin-Watson:                   1.979\n",
            "Prob(Omnibus):                  0.507   Jarque-Bera (JB):                1.386\n",
            "Skew:                           0.020   Prob(JB):                        0.500\n",
            "Kurtosis:                       2.958   Cond. No.                         102.\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [ 0.26828011  0.76783326 -0.50673142  0.47550265  0.43135642  0.12464959\n",
            " -0.11853882]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlm2hSAiHoMa",
        "outputId": "e3fb63ec-ba34-450e-a751-d3c9e8aa9e74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#SKlearn linear model\n",
        "\n",
        "from sklearn import linear_model\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(x_train,y_train)\n",
        "vars(regr)\n",
        "print('Model fit :',regr.coef_,regr.intercept_)\n",
        "print('True :     ',model_a,model_c)\n",
        "vars(regr)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model fit : [ 0.76783326 -0.50673142  0.47550265  0.43135642  0.12464959 -0.11853882] 0.2682801086081552\n",
            "True :      [ 0.76768127 -0.50678936  0.47532782  0.43127988  0.12477923 -0.1184996 ] 0.2644701633703223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_residues': 9822.754648000235,\n",
              " 'coef_': array([ 0.76783326, -0.50673142,  0.47550265,  0.43135642,  0.12464959,\n",
              "        -0.11853882]),\n",
              " 'copy_X': True,\n",
              " 'fit_intercept': True,\n",
              " 'intercept_': 0.2682801086081552,\n",
              " 'n_jobs': None,\n",
              " 'normalize': False,\n",
              " 'rank_': 6,\n",
              " 'singular_': array([10214.53788908, 10192.06087552, 10096.87001062,  9989.27379434,\n",
              "         9933.06566934,  9843.73287731])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkvvO1wYHoMb",
        "outputId": "147238f0-d4ac-419c-b5a5-ebb7d8843db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#optimise loss function. Need to combine a+c into the first parameter \n",
        "\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def cost(a,x,y):\n",
        "    predict = a[-1] + x@a[:-1]\n",
        "    return np.mean((predict-y)**2)\n",
        "\n",
        "opt_result = minimize(cost, np.zeros(num_features+1), args=(x_train,y_train),method='BFGS', options={'maxiter': 5000})\n",
        "print('Model fit :',opt_result.x[:-1],opt_result.x[-1])\n",
        "print('True :     ',model_a,model_c)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model fit : [ 0.76783325 -0.50673143  0.47550264  0.43135641  0.12464959 -0.11853883] 0.2682800907212365\n",
            "True :      [ 0.76768127 -0.50678936  0.47532782  0.43127988  0.12477923 -0.1184996 ] 0.2644701633703223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmsoAGzvHoMb"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}